library(tidyverse)
# Read the dataset
train_data <- read_csv("train.csv")
# Read the dataset
train_data <- read_csv("C:/Users/3921s/Desktop/NJIT/Spring 2023/Data analytics with R/HW/HW3/train.csv")
## A
# 1
# Load required libraries
library(tidyverse)
# Read the dataset
train_data <- read_csv("C:/Users/3921s/Desktop/NJIT/Spring 2023/Data analytics with R/HW/HW3/train.csv")
# Check the structure of the dataset
str(train_data)
# 1. Identify numerical and categorical features
numerical_features <- train_data %>% select_if(is.numeric)
cat_features <- train_data %>% select_if(is.character)
num_features_count <- length(names(numerical_features))
cat_features_count <- length(names(cat_features))
cat("Number of numerical features:", num_features_count, "\n")
cat("Number of categorical features:", cat_features_count, "\n")
# 2. Histogram for numerical features
for (feature in names(numerical_features)) {
ggplot(numerical_features, aes_string(x = feature)) +
geom_histogram(color = "black", fill = "blue", bins = 30) +
ggtitle(paste("Histogram of", feature)) +
theme_minimal() +
xlab(feature) +
ylab("Frequency") +
print()
}
# 2. Histogram for numerical features
for (feature in names(numerical_features)) {
ggplot(numerical_features, aes_string(x = feature)) +
geom_histogram(color = "black", fill = "blue", bins = 30) +
ggtitle(paste("Histogram of", feature)) +
theme_minimal() +
xlab(feature) +
ylab("Frequency") +
print()
}
# 3. Table for categorical features
for (feature in names(cat_features)) {
cat("\nTable for", feature, ":\n")
print(table(train_data[[feature]]))
}
##########################################################################
library(tidyverse)
library(ggplot2)
train_data <- read_csv("train.csv")
train_data <- read_csv("C:/Users/3921s/Desktop/NJIT/Spring 2023/Data analytics with R/HW/HW3/train.csv")
numerical_features <- select_if(train_data, is.numeric)
categorical_features <- select_if(train_data, is.factor)
num_numerical <- length(names(numerical_features))
num_categorical <- length(names(categorical_features))
cat("Number of numerical features:", num_numerical, "\n")
cat("Number of categorical features:", num_categorical, "\n")
# Plot each numerical feature using ggplot2 and save them as individual files
for (feature in names(numerical_features)) {
plot <- ggplot(train_data, aes_string(x = feature)) +
geom_histogram(binwidth = 30, fill = "lightblue", color = "black") +
labs(title = paste("Histogram of", feature), x = feature, y = "Frequency")
ggsave(paste0("histogram_", feature, ".png"), plot)
}
# Calculate frequency distribution for each categorical feature and save them as individual files
for (feature in names(categorical_features)) {
freq_table <- train_data %>%
group_by_at(vars(feature)) %>%
summarise(Frequency = n())
write.csv(freq_table, paste0("table_", feature, ".csv"))
}
library(tidyverse)
library(ggplot2)
train_data <- read_csv("C:/Users/3921s/Desktop/NJIT/Spring 2023/Data analytics with R/HW/HW3/train.csv")
numerical_features <- select_if(train_data, is.numeric)
categorical_features <- select_if(train_data, is.factor)
num_numerical <- length(names(numerical_features))
num_categorical <- length(names(categorical_features))
cat("Number of numerical features:", num_numerical, "\n")
cat("Number of categorical features:", num_categorical, "\n")
# Plot each numerical feature using ggplot2 and save them as individual files
for (feature in names(numerical_features)) {
plot <- ggplot(train_data, aes_string(x = feature)) +
geom_histogram(binwidth = 30, fill = "lightblue", color = "black") +
labs(title = paste("Histogram of", feature), x = feature, y = "Frequency")
ggsave(paste0("histogram_", feature, ".png"), plot)
}
# Calculate frequency distribution for each categorical feature and save them as individual files
for (feature in names(categorical_features)) {
freq_table <- train_data %>%
group_by_at(vars(feature)) %>%
summarise(Frequency = n())
write.csv(freq_table, paste0("table_", feature, ".csv"))
}
## A
# 1
########################################################################################################
library(tidyverse)
library(ggplot2)
train_data <- read_csv("C:/Users/3921s/Desktop/NJIT/Spring 2023/Data analytics with R/HW/HW3/train.csv")
#
numerical_features <- select_if(train_data, is.numeric)
categorical_features <- select_if(train_data, is.factor)
num_numerical <- length(names(numerical_features))
num_categorical <- length(names(categorical_features))
cat("Number of numerical features:", num_numerical, "\n")
cat("Number of categorical features:", num_categorical, "\n")
#
# Plot each numerical feature using ggplot2 and save them as individual files
for (feature in names(numerical_features)) {
plot <- ggplot(train_data, aes_string(x = feature)) +
geom_histogram(binwidth = 30, fill = "lightblue", color = "black") +
labs(title = paste("Histogram of", feature), x = feature, y = "Frequency")
ggsave(paste0("histogram_", feature, ".png"), plot)
}
#
# Calculate frequency distribution for each categorical feature and save them as individual files
for (feature in names(categorical_features)) {
freq_table <- train_data %>%
group_by_at(vars(feature)) %>%
summarise(Frequency = n())
write.csv(freq_table, paste0("table_", feature, ".csv"))
}
######################################################################
#2.4
# Load and attach the data set central.park
data(central.park)
attach(central.park)
# Make a table of the WX variable
table(WX)
# Make a table of the WX variable with exclude=FALSE
table(WX, exclude = FALSE)
# The second table is better as it also shows the NA values.
###################################################################
#2.8
# Load and attach the data set npdb
data(npdb)
attach(npdb)
# Make a table of the state variable
table(state)
# Find the state with the most awards
sort(table(state), decreasing = TRUE)[1]
#the state with most awards is CA
#####################################################################
#2.9
# Create a table of malpractice awards for each doctor
table(npdb$ID)
# Create a table of the number of doctors with each number of awards
table(table(ID))
#The command table(table(ID)) creates a table of the number of doctors with each number of awards.
#This is interesting because it allows us to see the distribution of awards among doctors and how many doctors have a certain number of awards.
######################################################################
#2.10
library(UsingR)
data(MLBattend)
# Extract wins for the New York Yankees
ny_wins <- with(MLBattend, wins[franchise == "NYA"])
# Add names 1969:2000
names(ny_wins) <- 1969:2000
# Barplot and dot chart
par(mfrow=c(2,1))
barplot(ny_wins, main="New York Yankees Wins (1969-2000)", xlab="Year", ylab="Number of Wins", col="blue")
plot(ny_wins, main="New York Yankees Wins (1969-2000)", xlab="Year", ylab="Number of Wins", col="red", pch=19)
#############################################################################
#2.16 leftttttttttt
# load the data set
data(rivers)
# 1. proportion of rivers less than 500 miles long
prop.table(sum(rivers < 500))
# 2. proportion of rivers less than the mean length
prop.table(sum(rivers < mean(rivers)))
# 3. 0.75 quantile
quantile(rivers, 0.75)
#########################################################################
#2.23
library(UsingR)
data(npdb)
# Mean and median award amount
mean_award <- mean(npdb$amount, na.rm = TRUE)
median_award <- median(npdb$amount, na.rm = TRUE)
mean_award
median_award
# Percentile of mean award
percentile_mean <- mean(npdb$amount <= mean_award) * 100
percentile_mean
###########################################################################
#2.30
library(UsingR)
data(bumpers)
data(firstchi)
data(math)
# Bumpers
hist(bumpers)
mean(bumpers)
median(bumpers)
sd(bumpers)
# Firstchi
hist(firstchi)
mean(firstchi)
median(firstchi)
sd(firstchi)
# Math
hist(math)
mean(math)
median(math)
sd(math)
#2.32
library(UsingR)
data(pi2000)
# Density estimate
plot(density(pi2000), main="Density Estimate of pi2000")
# Histogram with custom breaks
hist(pi2000, breaks=seq(0,10,by=0.5), main="Histogram of pi2000")
#2.34
library(MASS)
data(DDT)
# Histogram
hist(DDT, main="Histogram of DDT")
# Boxplot
boxplot(DDT, main="Boxplot of DDT")
# Mean and standard deviation
mean(DDT)
sd(DDT)
#2.35
# State abbreviations
state_abbr <- state.abb
# State areas
state_area <- state.area
# Rename state.area with state.abb
names(state_area) <- state_abbr
# Percent of states with area less than New Jersey (NJ)
percent_NJ <- mean(state_area < state_area["NJ"]) * 100
# Percent of states with area less than New York (NY)
percent_NY <- mean(state_area < state_area["NY"]) * 100
# Histogram of all data
hist(state_area, main="Histogram of State Areas")
# Identify outlier
outlier <- state_area > 500
#2.36
library(UsingR)
data(nym.2002)
hist(nym.2002$time)
#2.39
library(UsingR)
data(hall.fame)
hist(hall.fame$HR)
hist(hall.fame$BA)
hist(hall.fame$OBP)
#2.41
x <- rnorm(1000)
boxplot(x, range = 0.5, horizontal = TRUE)
boxplot(x, range = 1, horizontal = TRUE)
boxplot(x, range = 1.5, horizontal = TRUE)
boxplot(x, range = 2, horizontal = TRUE)
#2.42
library(UsingR)
data(cfb)
hist(cfb$AGE)
hist(cfb$EDUC)
hist(cfb$NETWORTH)
hist(log(cfb$SAVING + 1))
#2.43
library(UsingR)
data(brightness)
hist(brightness)
#2.44
library(UsingR)
data(lawsuits)
par(mfrow = c(2, 1))
hist(lawsuits)
hist(log(lawsuits))
boxplot(lawsuits, horizontal = TRUE)
boxplot(log(lawsuits), horizontal = TRUE)
par(mfrow = c(1, 1))
#2.45
library(UsingR)
data(exec.pay)
hist(exec.pay)
hist(log(1 + exec.pay), breaks = 30)
median(exec.pay)
mean(exec.pay)
median(log(1 + exec.pay))
mean(log(1 + exec.pay))
library(tidyverse)
library(ggplot2)
train_data <- read_csv("C:/Users/3921s/Desktop/NJIT/Spring 2023/Data analytics with R/HW/HW3/train.csv")
numerical_features <- select_if(train_data, is.numeric)
categorical_features <- select_if(train_data, is.factor)
num_numerical <- length(names(numerical_features))
num_categorical <- length(names(categorical_features))
cat("Number of numerical features:", num_numerical, "\n")
cat("Number of categorical features:", num_categorical, "\n")
# Plot each numerical feature using ggplot2 and save them as individual files
for (feature in names(numerical_features)) {
plot <- ggplot(train_data, aes_string(x = feature)) +
geom_histogram(binwidth = 30, fill = "lightblue", color = "black") +
labs(title = paste("Histogram of", feature), x = feature, y = "Frequency")
ggsave(paste0("histogram_", feature, ".png"), plot)
}
# Calculate frequency distribution for each categorical feature and save them as individual files
for (feature in names(categorical_features)) {
freq_table <- train_data %>%
group_by_at(vars(feature)) %>%
summarise(Frequency = n())
write.csv(freq_table, paste0("table_", feature, ".csv"))
}
######################################################################
#2.4
# Load and attach the data set central.park
data(central.park)
attach(central.park)
# Make a table of the WX variable
table(WX)
# Make a table of the WX variable with exclude=FALSE
table(WX, exclude = FALSE)
# Load and attach the data set npdb
data(npdb)
#2.4
# Load and attach the data set central.park
data(central.park)
attach(central.park)
# Make a table of the WX variable
table(WX)
# Make a table of the WX variable with exclude=FALSE
table(WX, exclude = FALSE)
# The second table is better as it also shows the NA values.
# Load and attach the data set npdb
data(npdb)
attach(npdb)
# Make a table of the state variable
table(state)
# Find the state with the most awards
sort(table(state), decreasing = TRUE)[1]
#2.9
# Create a table of malpractice awards for each doctor
table(npdb$ID)
# Load and attach the data set npdb
data(npdb)
# Load and attach the data set npdb
data(npdb)
attach(npdb)
# Make a table of the state variable
table(state)
# Find the state with the most awards
sort(table(state), decreasing = TRUE)[1]
#the state with most awards is CA
#2.9
# Create a table of malpractice awards for each doctor
table(npdb$ID)
# Create a table of the number of doctors with each number of awards
table(table(ID))
#The command table(table(ID)) creates a table of the number of doctors with each number of awards.
#This is interesting because it allows us to see the distribution of awards among doctors and how many doctors have a certain number of awards.
#2.9
# Create a table of malpractice awards for each doctor
table(npdb$ID)
# Create a table of the number of doctors with each number of awards
table(table(ID))
#The command table(table(ID)) creates a table of the number of doctors with each number of awards.
#This is interesting because it allows us to see the distribution of awards among doctors and how many doctors have a certain number of awards.
head(table)
#2.9
# Create a table of malpractice awards for each doctor
table(npdb$ID)
# Create a table of the number of doctors with each number of awards
table(table(ID))
#The command table(table(ID)) creates a table of the number of doctors with each number of awards.
#This is interesting because it allows us to see the distribution of awards among doctors and how many doctors have a certain number of awards.
#2.10
library(UsingR)
data(MLBattend)
# Extract wins for the New York Yankees
ny_wins <- with(MLBattend, wins[franchise == "NYA"])
# Add names 1969:2000
names(ny_wins) <- 1969:2000
# Barplot and dot chart
par(mfrow=c(2,1))
barplot(ny_wins, main="New York Yankees Wins (1969-2000)", xlab="Year", ylab="Number of Wins", col="blue")
plot(ny_wins, main="New York Yankees Wins (1969-2000)", xlab="Year", ylab="Number of Wins", col="red", pch=19)
#2.16 leftttttttttt
# load the data set
data(rivers)
# 1. proportion of rivers less than 500 miles long
prop.table(sum(rivers < 500))
# 2. proportion of rivers less than the mean length
prop.table(sum(rivers < mean(rivers)))
# 3. 0.75 quantile
quantile(rivers, 0.75)
#2.23
library(UsingR)
data(npdb)
# Mean and median award amount
mean_award <- mean(npdb$amount, na.rm = TRUE)
median_award <- median(npdb$amount, na.rm = TRUE)
mean_award
median_award
# Percentile of mean award
percentile_mean <- mean(npdb$amount <= mean_award) * 100
percentile_mean
#2.30
library(UsingR)
data(bumpers)
data(firstchi)
data(math)
# Bumpers
hist(bumpers)
mean(bumpers)
median(bumpers)
sd(bumpers)
# Firstchi
hist(firstchi)
mean(firstchi)
median(firstchi)
sd(firstchi)
# Math
hist(math)
mean(math)
median(math)
sd(math)
library(UsingR)
data(pi2000)
# Density estimate
plot(density(pi2000), main="Density Estimate of pi2000")
# Histogram with custom breaks
hist(pi2000, breaks=seq(0,10,by=0.5), main="Histogram of pi2000")
#2.34
library(MASS)
data(DDT)
# Histogram
hist(DDT, main="Histogram of DDT")
# Boxplot
boxplot(DDT, main="Boxplot of DDT")
# Mean and standard deviation
mean(DDT)
sd(DDT)
#2.35
# State abbreviations
state_abbr <- state.abb
# State areas
state_area <- state.area
# Rename state.area with state.abb
names(state_area) <- state_abbr
# Percent of states with area less than New Jersey (NJ)
percent_NJ <- mean(state_area < state_area["NJ"]) * 100
# Percent of states with area less than New York (NY)
percent_NY <- mean(state_area < state_area["NY"]) * 100
# Histogram of all data
hist(state_area, main="Histogram of State Areas")
# Identify outlier
outlier <- state_area > 500
#2.36
library(UsingR)
data(nym.2002)
hist(nym.2002$time)
#2.39
library(UsingR)
data(hall.fame)
hist(hall.fame$HR)
hist(hall.fame$BA)
hist(hall.fame$OBP)
#2.39
library(UsingR)
data(hall.fame)
hist(hall.fame$HR)
hist(hall.fame$BA)
hist(hall.fame$OBP)
#2.39
library(UsingR)
data(hall.fame)
hist(hall.fame$HR)
hist(hall.fame$BA)
hist(hall.fame$OBP)
#2.39
library(UsingR)
data(hall.fame)
hist(hall.fame$HR)
hist(hall.fame$BA)
hist(hall.fame$OBP)
#2.41
x <- rnorm(1000)
boxplot(x, range = 0.5, horizontal = TRUE)
boxplot(x, range = 1, horizontal = TRUE)
boxplot(x, range = 1.5, horizontal = TRUE)
boxplot(x, range = 2, horizontal = TRUE)
#2.42
library(UsingR)
data(cfb)
hist(cfb$AGE)
hist(cfb$EDUC)
hist(cfb$NETWORTH)
hist(log(cfb$SAVING + 1))
#2.43
library(UsingR)
data(brightness)
hist(brightness)
#2.44
library(UsingR)
data(lawsuits)
par(mfrow = c(2, 1))
hist(lawsuits)
hist(log(lawsuits))
boxplot(lawsuits, horizontal = TRUE)
boxplot(log(lawsuits), horizontal = TRUE)
par(mfrow = c(1, 1))
#2.45
library(UsingR)
data(exec.pay)
hist(exec.pay)
hist(log(1 + exec.pay), breaks = 30)
median(exec.pay)
mean(exec.pay)
median(log(1 + exec.pay))
mean(log(1 + exec.pay))
